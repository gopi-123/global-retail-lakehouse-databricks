{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d3c1e5c8-b45b-4c2d-8f0c-9e811a065738",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "- Create the Silver layer customer table if it does not exist.\n",
    "- Identify the maximum `last_updated` timestamp from the Silver layer table.\n",
    "- Create a temporary view `bronze_incremental` to pull new data from the Bronze layer.\n",
    "- Apply business rules and transformations:\n",
    "  - Validate email addresses.\n",
    "  - Ensure age is between 18 and 100.\n",
    "  - Create customer segments based on total purchase.\n",
    "  - Calculate days since user registration.\n",
    "  - Remove records with negative total purchase.\n",
    "- Merge the transformed data into the Silver layer customer table based on customer ID.\n",
    "So, that's how we have load the data from bronze layer. We have clean and transform the data. And then, finally, we have saved it into our silver layer.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "991db716-d9d8-46c0-9c19-a057c02fd7fc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "- Switches to the 'globalretail_silver' database.\n",
    "- Creates the 'silver_customers' table if it does not exist, with columns for customer details, segmentation, and metadata.\n",
    "\"\"\"\n",
    "spark.sql(\"USE globalretail_silver\")\n",
    "spark.sql(\"\"\"\n",
    "    CREATE TABLE IF NOT EXISTS silver_customers (\n",
    "    customer_id STRING,\n",
    "    name STRING,\n",
    "    email STRING,\n",
    "    country STRING,\n",
    "    customer_type STRING,\n",
    "    registration_date DATE,\n",
    "    age INT,\n",
    "    gender STRING,\n",
    "    total_purchases INT,\n",
    "    customer_segment STRING,\n",
    "    days_since_registration INT,\n",
    "    last_updated TIMESTAMP)\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "50495b0f-ff37-4fcf-89f9-3c490c96687d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "- Retrieves the maximum 'last_updated' timestamp from the 'silver_customers' table.\n",
    "- Sets 'last_processed_timestamp' to the retrieved value, or to a default if no value exists.\n",
    "\"\"\"\n",
    "# Get the last processed timestamp from silver layer\n",
    "last_processed_df = spark.sql(\"SELECT MAX(last_updated) as last_processed FROM silver_customers\")\n",
    "last_processed_timestamp = last_processed_df.collect()[0]['last_processed']\n",
    "\n",
    "if last_processed_timestamp is None:\n",
    "    last_processed_timestamp = \"1900-01-01T00:00:00.000+00:00\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0912b33f-1ce2-4c77-8ade-9920736d3a4d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "- Creates or replaces a temporary view named 'bronze_incremental' containing only new records from the Bronze layer.\n",
    "- The view filters records from 'globalretail_bronze.bronze_customer' where 'ingestion_timestamp' is greater than the last processed timestamp.\n",
    "- A temporary view in Databricks is a logical table that exists only within the current notebook session and is not persisted to the database.\n",
    "- This allows downstream processing of only the new or updated customer records since the last pipeline run.\n",
    "\"\"\"\n",
    "# Create a temporary view of incremental bronze data\n",
    "spark.sql(f\"\"\"\n",
    "CREATE OR REPLACE TEMPORARY VIEW bronze_incremental AS\n",
    "SELECT *\n",
    "FROM globalretail_bronze.bronze_customer c where  c.ingestion_timestamp > '{last_processed_timestamp}'\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "577feee7-d342-469b-b134-98bdd2317861",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "- Displays the contents of the 'bronze_incremental' temporary view containing new or updated customer records from the Bronze layer.\n",
    "\"\"\"\n",
    "display(spark.sql(\"select * from bronze_incremental\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "36e30c14-fe7f-415c-8e93-a2421b6e3973",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "- Validate email addresses (null or not null).\n",
    "- Ensure valid age is between 18 and 100.\n",
    "- Create customer_segment: 'High Value' if total_purchases > 10000, 'Medium Value' if > 5000, else 'Low Value'.\n",
    "- Calculate days since user registration. (since user is registered in the system)\n",
    "- Remove records where total_purchase is negative. (Remove any junk records where total_purchase is negative number)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ac559d21-92d5-4ddf-9f3f-d5d9c120b1f2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "- Creates or replaces a temporary view 'silver_incremental' with transformed customer data from 'bronze_incremental'.\n",
    "- Applies business rules:\n",
    "    - Validates email is not null.\n",
    "    - Ensures age is between 18 and 100.\n",
    "    - Removes records with negative total_purchases.\n",
    "    - Segments customers by total_purchases.\n",
    "    - Calculates days since registration using DATEDIFF(endDate, startDate): returns the number of days from startDate to endDate.\n",
    "      Example: DATEDIFF(CURRENT_DATE(), registration_date) gives days since registration.\n",
    "    - Adds current timestamp as last_updated using CURRENT_TIMESTAMP().\n",
    "    - Other useful functions:\n",
    "        - DATE_ADD(date, days): adds days to a date.\n",
    "        - DATE_SUB(date, days): subtracts days from a date.\n",
    "        - DATE_FORMAT(date, format): formats a date as a string.\n",
    "        - TIMESTAMPDIFF(unit, start, end): difference between two timestamps in specified units.\n",
    "\"\"\"\n",
    "spark.sql(\"\"\"\n",
    "CREATE OR REPLACE TEMPORARY VIEW silver_incremental AS\n",
    "SELECT\n",
    "    customer_id,\n",
    "    name,\n",
    "    email,\n",
    "    country,\n",
    "    customer_type,\n",
    "    registration_date,\n",
    "    age,\n",
    "    gender,\n",
    "    total_purchases,\n",
    "    CASE\n",
    "        WHEN total_purchases > 10000 THEN 'High Value'\n",
    "        WHEN total_purchases > 5000 THEN 'Medium Value'\n",
    "        ELSE 'Low Value'\n",
    "    END AS customer_segment,\n",
    "    DATEDIFF(CURRENT_DATE(), registration_date) AS days_since_registration,\n",
    "    CURRENT_TIMESTAMP() AS last_updated\n",
    "FROM bronze_incremental\n",
    "WHERE \n",
    "    age BETWEEN 18 AND 100\n",
    "    AND email IS NOT NULL\n",
    "    AND total_purchases >= 0\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "707aaf5e-a173-4e6b-9d3e-6680e1fa22a4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "- Displays the transformed customer data in 'silver_incremental'.\n",
    "- Business rules applied:\n",
    "    - New 'customer_segment' column added: 'High Value' if total_purchases > 10000, 'Medium Value' if > 5000, else 'Low Value'.\n",
    "    - Only includes records where age is between 18 and 100.\n",
    "    - Only includes records where email is not null.\n",
    "    - Removes records with negative total_purchases.\n",
    "\"\"\"\n",
    "display(spark.sql(\"select * from silver_incremental\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0ff5c70a-4bb8-4fef-8364-aaa01e8cc5ad",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Summary:\n",
    "- This script merges cleaned and transformed customer data from the 'silver_incremental' view into the 'silver_customers' table in the Silver layer.\n",
    "- The merge operation uses 'customer_id' as the unique key.\n",
    "- If a customer_id already exists in the target table, the record is updated; if not, a new record is inserted.\n",
    "\n",
    "Why use MERGE instead of APPEND:\n",
    "- Using MERGE ensures that existing records are updated with the latest information, preventing duplicate entries for the same customer.\n",
    "- APPEND would add new rows regardless of duplicates, leading to data redundancy and inconsistency.\n",
    "- MERGE provides idempotency: re-running the script does not create duplicate records and only updates or inserts as needed.\n",
    "\"\"\"\n",
    "\n",
    "spark.sql(\"\"\"\n",
    "MERGE INTO silver_customers target\n",
    "USING silver_incremental source\n",
    "ON target.customer_id = source.customer_id\n",
    "WHEN MATCHED THEN\n",
    "    UPDATE SET *\n",
    "WHEN NOT MATCHED THEN\n",
    "    INSERT *\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e0b7c3d9-65d0-464b-9c2e-6a1ddf501996",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "- Displays the total number of records in the 'silver_customers' table.\n",
    "So, that's how we have load the data from bronze layer. We have clean and transform the data. And then, finally, we have saved it into our silver layer.\n",
    "\"\"\"\n",
    "display(spark.sql(\"select count(*) from silver_customers\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a51f6b0b-a7f8-4647-afb9-024bc5a4e274",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "Silverlayer_customer_load",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
